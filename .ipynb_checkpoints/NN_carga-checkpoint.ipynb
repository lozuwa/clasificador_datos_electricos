{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-aa2efaa45fb1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mStandardScaler\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'sklearn'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from NN import NeuralNetwork"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    \"\"\"\n",
    "    Carga de los datos\n",
    "    \"\"\"\n",
    "    inputs= pd.read_excel('INPUT_OUTPUT_CORREGIDO.xlsx',sheetname='INPUT')\n",
    "    inputs.drop('PSTO',axis=1,inplace=True)\n",
    "    \n",
    "    output= pd.read_excel('INPUT_OUTPUT_CORREGIDO.xlsx',sheetname='OUTPUT')\n",
    "    return inputs,output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing_data(X_train,X_valid,X_test):\n",
    "    \"\"\"\n",
    "    Preprocesamiento de los datos\"\"\"\n",
    "    \n",
    "    scaler= StandardScaler()\n",
    "    X_train= scaler.fit_transform(X_train)\n",
    "    X_valid= scaler.transform(X_valid)\n",
    "    X_test= scaler.transform(X_test)\n",
    "    \n",
    "    return X_train, X_valid, X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MSE(y, Y):\n",
    "    \"\"\"Calcula Mean Squared Error\"\"\"\n",
    "    return 1/2*np.mean((y-Y)**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carga de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PAVILION\\Anaconda3\\envs\\py36\\lib\\site-packages\\pandas\\io\\excel.py:329: FutureWarning: The `sheetname` keyword is deprecated, use `sheet_name` instead\n",
      "  **kwds)\n",
      "C:\\Users\\PAVILION\\Anaconda3\\envs\\py36\\lib\\site-packages\\sklearn\\preprocessing\\data.py:617: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\PAVILION\\Anaconda3\\envs\\py36\\lib\\site-packages\\sklearn\\base.py:462: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "C:\\Users\\PAVILION\\Anaconda3\\envs\\py36\\lib\\site-packages\\ipykernel_launcher.py:7: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  import sys\n",
      "C:\\Users\\PAVILION\\Anaconda3\\envs\\py36\\lib\\site-packages\\ipykernel_launcher.py:8: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "inputs, output = load_data()\n",
    "\n",
    "X_train, X_test, y_train, y_test =train_test_split(inputs,output, test_size=0.2, random_state=0)\n",
    "X_valid, X_test, y_valid, y_test= train_test_split(X_test, y_test, test_size=0.25, random_state=0)\n",
    "\n",
    "X_train, X_valid, X_test= preprocessing_data(X_train, X_valid, X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteración: 100 ... Train error: 0.0263 ... Validation error: 0.0239\n",
      "Iteración: 200 ... Train error: 0.0246 ... Validation error: 0.0227\n",
      "Iteración: 300 ... Train error: 0.0244 ... Validation error: 0.0226\n",
      "Iteración: 400 ... Train error: 0.0243 ... Validation error: 0.0226\n",
      "Iteración: 500 ... Train error: 0.0242 ... Validation error: 0.0225\n",
      "Iteración: 600 ... Train error: 0.0241 ... Validation error: 0.0224\n",
      "Iteración: 700 ... Train error: 0.024 ... Validation error: 0.0223\n",
      "Iteración: 800 ... Train error: 0.024 ... Validation error: 0.0222\n",
      "Iteración: 900 ... Train error: 0.0239 ... Validation error: 0.0221\n",
      "Iteración: 1000 ... Train error: 0.0238 ... Validation error: 0.0221\n",
      "Iteración: 1100 ... Train error: 0.0237 ... Validation error: 0.022\n",
      "Iteración: 1200 ... Train error: 0.0237 ... Validation error: 0.0219\n",
      "Iteración: 1300 ... Train error: 0.0236 ... Validation error: 0.0219\n",
      "Iteración: 1400 ... Train error: 0.0235 ... Validation error: 0.0218\n",
      "Iteración: 1500 ... Train error: 0.0234 ... Validation error: 0.0217\n",
      "Iteración: 1600 ... Train error: 0.0234 ... Validation error: 0.0217\n",
      "Iteración: 1700 ... Train error: 0.0233 ... Validation error: 0.0216\n",
      "Iteración: 1800 ... Train error: 0.0232 ... Validation error: 0.0216\n",
      "Iteración: 1900 ... Train error: 0.0232 ... Validation error: 0.0215\n",
      "Iteración: 2000 ... Train error: 0.0231 ... Validation error: 0.0214\n",
      "Iteración: 2100 ... Train error: 0.023 ... Validation error: 0.0214\n",
      "Iteración: 2200 ... Train error: 0.023 ... Validation error: 0.0213\n",
      "Iteración: 2300 ... Train error: 0.0229 ... Validation error: 0.0212\n",
      "Iteración: 2400 ... Train error: 0.0229 ... Validation error: 0.0212\n",
      "Iteración: 2500 ... Train error: 0.0228 ... Validation error: 0.0211\n",
      "Iteración: 2600 ... Train error: 0.0227 ... Validation error: 0.0211\n",
      "Iteración: 2700 ... Train error: 0.0227 ... Validation error: 0.021\n",
      "Iteración: 2800 ... Train error: 0.0226 ... Validation error: 0.0209\n",
      "Iteración: 2900 ... Train error: 0.0225 ... Validation error: 0.0209\n",
      "Iteración: 3000 ... Train error: 0.0225 ... Validation error: 0.0208\n",
      "Iteración: 3100 ... Train error: 0.0224 ... Validation error: 0.0208\n",
      "Iteración: 3200 ... Train error: 0.0223 ... Validation error: 0.0207\n",
      "Iteración: 3300 ... Train error: 0.0223 ... Validation error: 0.0206\n",
      "Iteración: 3400 ... Train error: 0.0222 ... Validation error: 0.0206\n",
      "Iteración: 3500 ... Train error: 0.0222 ... Validation error: 0.0205\n",
      "Iteración: 3600 ... Train error: 0.0221 ... Validation error: 0.0205\n",
      "Iteración: 3700 ... Train error: 0.022 ... Validation error: 0.0204\n",
      "Iteración: 3800 ... Train error: 0.022 ... Validation error: 0.0203\n",
      "Iteración: 3900 ... Train error: 0.0219 ... Validation error: 0.0203\n",
      "Iteración: 4000 ... Train error: 0.0219 ... Validation error: 0.0202\n",
      "Iteración: 4100 ... Train error: 0.0218 ... Validation error: 0.0202\n",
      "Iteración: 4200 ... Train error: 0.0217 ... Validation error: 0.0201\n",
      "Iteración: 4300 ... Train error: 0.0217 ... Validation error: 0.02\n",
      "Iteración: 4400 ... Train error: 0.0216 ... Validation error: 0.02\n",
      "Iteración: 4500 ... Train error: 0.0216 ... Validation error: 0.0199\n",
      "Iteración: 4600 ... Train error: 0.0215 ... Validation error: 0.0199\n",
      "Iteración: 4700 ... Train error: 0.0215 ... Validation error: 0.0198\n",
      "Iteración: 4800 ... Train error: 0.0214 ... Validation error: 0.0198\n",
      "Iteración: 4900 ... Train error: 0.0213 ... Validation error: 0.0197\n",
      "Iteración: 5000 ... Train error: 0.0213 ... Validation error: 0.0197\n"
     ]
    }
   ],
   "source": [
    "dimensions= [4,10,1]\n",
    "learning_rate= 0.08\n",
    "iterations=5000\n",
    "min_valid_loss= np.inf\n",
    "\n",
    "model= NeuralNetwork(dimensions,learning_rate)\n",
    "\n",
    "for i in range(1,iterations+1):\n",
    "    model.train(X_train, y_train.values)\n",
    "    \n",
    "    train_loss= MSE(model.test(X_train),y_train.values)\n",
    "    valid_loss= MSE(model.test(X_valid),y_valid.values)\n",
    "    if valid_loss< min_valid_loss:\n",
    "        best_params= model.parameters\n",
    "        min_valid_loss= valid_loss\n",
    "        \n",
    "        with open('best_params.pickle', 'wb') as file:\n",
    "            pickle.dump(best_params, file)\n",
    "            \n",
    "    if i % 100 ==0:\n",
    "        print('Iteración: {} ... Train error: {} ... Validation error: {}'.format(i,round(train_loss,4), round(valid_loss,4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test error: 0.02399\n"
     ]
    }
   ],
   "source": [
    "with open('best_params.pickle', 'rb') as file:\n",
    "    best_params = pickle.load(file)\n",
    "    \n",
    "model.parameters= best_params\n",
    "test_pred=model.test(X_test)\n",
    "print('Test error:', round(MSE(test_pred,y_test.values),5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
